{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.embeddings import BedrockEmbeddings\n",
    "import boto3\n",
    "import botocore\n",
    "# os.environ['LANGCHAIN_TRACING_V2']='true'\n",
    "# os.environ['LANGCHAIN_ENDPOINT']=\"https://api.smith.langchain.com\"\n",
    "# os.environ['LANGCHAIN_API_KEY']=\"ls__cb0ee22e50e34241896c1c8230a9e218\"\n",
    "# os.environ['LANGCHAIN_PROJECT']=\"demo\"\n",
    "\n",
    "config = botocore.config.Config(\n",
    "    read_timeout=900,\n",
    "    connect_timeout=900,\n",
    "    retries={\"max_attempts\": 0}\n",
    ")\n",
    "\n",
    "bedrock_client = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    region_name=\"us-east-1\",\n",
    "    config=config,\n",
    ")\n",
    "file = (r\"C:\\Users\\Lenovo\\Documents\\Project-vs code\\Amazon Transcribe\\2-Cloumn page\\WET_2013041616211199.pdf\")\n",
    "loader = PyPDFLoader(file)\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=600,chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(docs)\n",
    "\n",
    "embeddings = BedrockEmbeddings()\n",
    "db = FAISS.from_documents(documents=texts,embedding=embeddings)\n",
    "\n",
    "template = \"\"\"\n",
    "Answer truthfull based on the given text only\n",
    "\n",
    "\n",
    "{context}\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "retriever = db.as_retriever(search_type='similarity', search_kwargs={\"k\": 3})\n",
    "llm = Bedrock(model_id=\"anthropic.claude-v2:1\",client=bedrock_client,model_kwargs = {\"temperature\":1e-10,\"max_tokens_to_sample\": 8191})\n",
    "qa_prompt = PromptTemplate(template=template, input_variables=[\"context\",\"question\"])\n",
    "chain_type_kwargs = { \"prompt\": qa_prompt, \"verbose\": False }\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs=chain_type_kwargs,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
